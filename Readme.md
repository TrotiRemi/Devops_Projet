# Projet FFA - Dashboard F√©d√©ration Fran√ßaise Athl√©tisme

## Somaire

- [User Guide](#user-guide)

- [Data](#data)
  - [Structure du projet](#structure-du-projet)
  - [Introduction](#introduction)
  - [Description des fichiers](#description-des-fichiers)
  - [Rapport d'analyse](#rapport-danalyse)
    - [Page d'accueil](#page-daccueil)
    - [Page coureur](#page-coureur)
    - [Page course](#page-course)
    - [Page map](#page-map)
    - [Page histogramme](#page-histogramme)
    - [Exemple d'utilisation du dashboard](#exemple-dutilisation-du-dashboard)

- [DevOps](#devops)
  - [Structure DevOps](#structure-devops)
  - [Fichiers DevOps](#fichiers-devops)
  - [Ouverture des instances AWS](#ouverture-des-instances-aws)
  - [Gestion des droits d‚Äôacc√®s](#gestion-des-droits-dacces)
  - [Lancement de GitHub et Configuration CI/CD](#lancement-de-github-et-configuration-cicd)
  - [Installation des packages](#installation-des-packages)
  - [Importation des donn√©es dans Elasticsearch](#importation-des-donnees-dans-elasticsearch)
  - [Cr√©ation du Cluster Kubernetes](#creation-du-cluster-kubernetes)
  - [Configuration et explication des fichiers Kubernetes](#configuration-et-explication-des-fichiers-kubernetes)
  - [Acc√®s √† l'application](#acces-a-lapplication)
  - [Conclusion](#conclusion)

---



#
# USER GUIDE

Ce projet combine deux projet en un. C'est d'abord un projet de devops ou je cr√©√©e un serveur sur AWS pour √©berger un application web. C'est aussi un projet de data avec plus de 1 000 000 de donn√©es qui sont rang√© dans ce m√™me serveur. Plusieurs fa√ßon de lancer le projet. En interne, sur une machine local. Apr√®s avoir install√© MongoDb, ElasticSearch et docker/docker-compose, on peut lancer la commande docker-compose up --build, pour ainsi lancer le projet. Ensuite il suffit d'ouvrir son navigateur sur localhost:8060 pour voir le projet. On peut aussi lancer en externe, en ouvrant mon instance AWS (details du fonctionnement apr√®s), et en lanceant depuis un terminal connect√© √† ce serveur, mon application. Elle est alors conn√©ct√© √† "IP_Serveur:8060" acc√©sible depuis toute connexion internet sans restriction (√ßa ne marche pas sur le wifi de l'Esiee par exemple).

#
# DATA


Nous avons choisis de scrapper le site de la FFA pour ce projet voici l'url : "https://bases.athle.fr/asp.net/liste.aspx?frmpostback=true&frmbase=calendrier&frmmode=1&frmespace=0"

N√©anmoins, pour scrapper nos donn√©es nous avons utilis√© cet url comme une base avant de faire une concat√©nation d'url avec les saisons, types et niveaux sur le site de la FFA.

Voici une capture d'√©cran du code r√©alisant cela :

![](Images/scrapp.png)


#
# DEVELOPER GUIDE

## Structure du projet
![Structure1](Images/Structure1.png)






![](Images/Structure2.png)

## Architecture du code

```mermaid
flowchart TB
    main --> utils
    main --> ffa_data
    main --> src
    utils --> docker
    ffa_data --> assets
    ffa_data --> data
    ffa_data --> ffa
    ffa --> ffa_spiders
    ffa --> ffa_items
    ffa --> ffa_middlewares
    ffa --> ffa_pipelines
    ffa --> ffa_settings
    ffa --> ffa_scrapy
    src --> components
    src --> pages
    components --> components_init
    components --> footer
    components --> header
    components --> navbar
    components --> search
    pages --> pages_init
    pages --> course
    pages --> histogram
    pages --> map
```



## Introduction

Ce projet est une application web interactive construite avec Dash pour la visualisation et l'analyse des performances de coureurs et des comp√©titions de marathon. L'application utilise Elasticsearch pour g√©rer et rechercher des donn√©es de comp√©titions et de coureurs, et MongoDB pour stocker les r√©sultats de course.

L'objectif de l'application est d'offrir une interface simple permettant √† l'utilisateur de rechercher des coureurs et des comp√©titions, de visualiser des cartes g√©ographiques et des graphiques statistiques.

## Description des Fichiers

### main.py

Description : Fichier principal de l'application Dash. Il initialise le serveur Dash et enregistre les pages disponibles. Le layout principal utilise dcc.Location et dash.page_container pour rendre dynamiquement les pages.
Responsabilit√© : D√©marrer l'application Dash et g√©rer le routage des pages.

### docker-compose.yaml

Description : Fichier de configuration Docker qui d√©finit les services n√©cessaires √† l'application. Il configure MongoDB, Elasticsearch, et l'application elle-m√™me (conteneur app-service).
Responsabilit√© : Orchestrer les diff√©rents services n√©cessaires au fonctionnement de l'application, y compris la base de donn√©es et le serveur web.

### Dockerfile
Description : Ce fichier d√©finit l'environnement de conteneur pour l'application, installant les d√©pendances et copiant les fichiers n√©cessaires √† l'application.
Responsabilit√© : Cr√©er un conteneur Docker qui ex√©cutera l'application Dash avec toutes ses d√©pendances.

### Mongo_Elastic.py
Description : Ce fichier synchronise les donn√©es entre MongoDB et Elasticsearch. Il r√©cup√®re les donn√©es de MongoDB, les transforme et les ins√®re dans Elasticsearch.
Responsabilit√© : Synchroniser les donn√©es entre MongoDB et Elasticsearch, g√©rer l'indexation des documents dans Elasticsearch.

## SRC

### Utils

Les fichiers ici contiennent des fonctions utilitaires pour l'interaction avec les bases de donn√©es et la gestion des donn√©es.

**get_data.py**

Description : Contient la fonction extract_Http(url) qui t√©l√©charge et extrait un fichier ZIP contenant des donn√©es CSV. Ces donn√©es sont ensuite sauvegard√©es dans le dossier data/rawdata.
Responsabilit√© : T√©l√©charger et extraire des fichiers CSV √† partir d'une URL fournie.

**get_Json.py**

Description : Contient la fonction extract_GeoJson(url) qui t√©l√©charge et charge un fichier GeoJSON √† partir d'une URL.
Responsabilit√© : T√©l√©charger et charger des fichiers GeoJSON pour l'application.

**Utils.py**

Description : Ce fichier contient plusieurs fonctions utilitaires essentielles pour l'application, y compris la gestion des donn√©es g√©ographiques et des recherches dans Elasticsearch.
Responsabilit√© : G√©rer les op√©rations comme le chargement des donn√©es g√©ographiques, la recherche dans Elasticsearch, et la g√©n√©ration des cartes.

### Components
Les composants du dashboard se trouvent dans ce dossier. Ils comprennent la barre de navigation, l'en-t√™te et le pied de page.

**navbar.py**

Description : D√©finit la barre de navigation du site, permettant √† l'utilisateur de naviguer entre les diff√©rentes pages.
Responsabilit√© : G√©rer les liens de navigation et l'apparence de la barre de navigation.

**header.py**

Description : Contient le titre principal du site.
Responsabilit√© : Afficher un titre centr√© en haut de la page.

**footer.py**

Description : Contient le pied de page avec des informations sur les auteurs et le projet.
Responsabilit√© : Fournir un pied de page avec des informations sur l'√©quipe de d√©veloppement et l'ann√©e de cr√©ation.

### Pages

Les pages du dashboard sont d√©finies ici.

**Coureur.py**

Description : Permet √† l'utilisateur de rechercher des coureurs en fonction de diff√©rents crit√®res (pr√©nom, nom, club, etc.). Les r√©sultats sont r√©cup√©r√©s de Elasticsearch et affich√©s sous forme de tableau.
Responsabilit√© : G√©rer la recherche des coureurs et afficher les r√©sultats dynamiquement.

**Course.py**

Description : Permet de rechercher des comp√©titions selon des crit√®res (nom, niveau, d√©partement). Les r√©sultats sont affich√©s sous forme de tableau.
Responsabilit√© : G√©rer la recherche des comp√©titions et afficher les r√©sultats.

**Map.py**

Description : Affiche une carte des d√©partements fran√ßais avec des informations sur les coureurs et les comp√©titions. Utilise la fonction generate_map() pour g√©n√©rer la carte.
Responsabilit√© : G√©rer l'affichage des cartes interactives.

**Histogram.py**

Description : Affiche des histogrammes qui analysent les performances des coureurs en fonction des distances parcourues et des temps de course. Utilise Plotly pour afficher des graphiques dynamiques.
Responsabilit√© : G√©rer l'affichage des histogrammes pour l'analyse des performances.

## Fonctionnalit√©s et Interactions

### Interactivit√©
L'application utilise des √©l√©ments interactifs comme :

dcc.Input et dcc.Dropdown pour les recherches et les filtres dynamiques.
dcc.Graph pour afficher des graphiques et des cartes g√©n√©r√©es par Plotly.

### Callbacks
Les callbacks sont utilis√©s pour rendre l'application interactive. Par exemple :

Les r√©sultats de recherche sont mis √† jour en fonction des crit√®res de l'utilisateur.
Les graphiques et cartes sont mis √† jour dynamiquement en fonction des s√©lections de l'utilisateur.

### Gestion des donn√©es
Les donn√©es sont r√©cup√©r√©es depuis Elasticsearch et MongoDB, et utilis√©es pour g√©n√©rer des cartes et des graphiques. Les donn√©es de MongoDB sont synchronis√©es avec Elasticsearch pour permettre une recherche rapide et efficace.


#
# Rapport d'analyse

Dans cette section nous allons vous partager diff√©rentes informations sur les pages du dashboard.

## Page d'accueil

![](Images/Accueil.png)

La page d‚Äôaccueil de notre application a √©t√© soigneusement con√ßue pour offrir une exp√©rience utilisateur fluide, intuitive et visuellement attrayante. D√®s l‚Äôarriv√©e sur la plateforme, l‚Äôutilisateur est accueilli par une interface moderne et √©pur√©e, mettant en avant les diff√©rentes fonctionnalit√©s essentielles pour explorer et analyser les performances des coureurs et comp√©titions. L‚Äôensemble du design de l‚Äôapplication a √©t√© cr√©√© et import√©, garantissant une identit√© visuelle coh√©rente et une exp√©rience immersive.

## Page Coureur

![](Images/Coureur.png)

Cette premi√®re page vous permet de chercher les r√©sultats d'un coureur √† l'aide de ce nom et/ou prenom. Vous pouvez aussi chercher les r√©sultats des coureurs d'un club. De plus, pour ces coureurs, vous pouvez suivre leur r√©sultats sur des plages de distances ou de dates pour une recherche approfondi. N√©anmoins voici une petite indication pour utiliser la recherche correctement, lors d'une recherche par date, il est obligatoire d'indiquer une ann√©e si un mois est renseign√©, de m√™me il est obligatoire d'indiquer un mois si un jour est renseign√©.

## Page Course

![](Images/Courses.png)

Cette seconde page permet d'√©tudier cette fois les courses et non pas les coureurs. L'utilisateur peut chercher selon un syst√®me de date qui est le m√™me que sur la page pr√©c√®dente. La recherche peut aussi √™tre pr√©cis√© selon le nom de la course, le niveau de cette derni√®re ou bien encore le d√©partement o√π elle a lieu.
 
## Page Map

![](Images/carte.png)

Cette page permet d'avoir une vision d'ensemble de la r√©partition des coureurs en France selon les d√©partements. On peut ainsi y voir quels sont les d√©partements comp√©titifs en France pour la course. Les zones non rensign√©es par une couleur indiquent une absence de donn√©e pour les √©valuer. 

## Page Histogramme

![](Images/Histogram.png)

Cette page permet d'observer la distribution des r√©sultats pour la course choisie, ainsi les athl√®tes peuvent se situer en terme de r√©sultats. On peut bien √©videmment choisir la distance de chaque course lors de la recherche.

## Exemple d'utilisation du dashboard

Le but de ce dashboard est de pouvoir trouver ses r√©sultats sur la premi√®re page en tant que coureur. Ensuite on peut rechercher la course en question pour l'√©tudier (nombre de coureur etc). Enfin, gr√¢ce √† la page histogramme, on peut examiner la distribution des r√©sultats pour se situer dans le niveau de la course. Ainsi chaque coureur peut effectuer une analyse approfondi de ses rsultats sur chaque course qu'il a effectu√©. 
# DevOps

## **DEVELOPER GUIDE DEVOPS**

### **Structure DevOps**
Ce projet suit une architecture DevOps permettant le d√©ploiement automatis√© d'une application web bas√©e sur **Dash**, avec **MongoDB** et **Elasticsearch** comme bases de donn√©es. L'ensemble est orchestr√© via **Kubernetes** sur un cluster AWS EKS.

---

## **Fichiers DevOps**
Le projet contient plusieurs fichiers cl√©s pour l'automatisation du d√©ploiement et la gestion de l'infrastructure :
- **Dockerfile** : Conteneurisation de l'application Dash.
- **docker-compose.yaml** : Configuration pour lancer les services en local.
- **kubernetes/** : Contient les fichiers de configuration pour Kubernetes.
- **.github/workflows/deploy.yml** : Pipeline CI/CD pour l'automatisation du build et du d√©ploiement.
- **src/** : Code source de l'application Dash.
- **data/** : Contient les fichiers CSV de backup et d'importation.
- **Images/** : Contient les images utiles pour la documentation.

---

## **Ouverture des instances AWS**
### **Cr√©ation et configuration de l'instance**
J'ai choisi une instance **m5.large**, capable de supporter la charge de l'application et les bases de donn√©es. Une fois l'instance cr√©√©e, j'ai attribu√© une cl√© `.pem` et me suis connect√© via la commande :
```sh
ssh -i Key_FFA.pem ec2-user@<IP_Serveur>
```
Ensuite, j'ai copi√© mon projet sur le serveur avec :
```sh
scp -i Key_FFA.pem -r Devops_project ec2-user@<IP_Serveur>:/home/ec2-user/
```

### **Configuration du pare-feu et des r√®gles d'acc√®s**
J'ai d√©fini des **Security Groups** pour ouvrir les ports n√©cessaires :
- **22** : SSH (acc√®s distant)
- **8060** : Acc√®s √† l'application Dash
- **80** : HTTP (pour Kubernetes LoadBalancer)

üìå *Configuration des r√®gles de s√©curit√© sur AWS :*
![](Images/Cl√©_Acc√©s_User.png)

---

## **Gestion des droits dacces**
Les acc√®s sont s√©curis√©s via plusieurs niveaux :
1. **IAM Roles & Policies** :
   - Un utilisateur AWS avec **IAM** a √©t√© cr√©√© avec des acc√®s restreints √† **EC2**, **EKS** et **S3**.
   - Seules les actions essentielles (cr√©ation de pods, acc√®s aux logs) sont permises.
  
2. **Security Groups** :
   - Seuls certains **IPs autoris√©s** peuvent acc√©der √† SSH et √† l'application via HTTP/HTTPS.
   - Le **port 8060** est expos√© uniquement au monde ext√©rieur pour l'application Dash.

3. **Kubernetes RBAC** :
   - L‚Äôacc√®s aux pods et services est restreint via des **RoleBindings** sur Kubernetes.
   - Seuls les utilisateurs avec les bons droits peuvent ex√©cuter `kubectl get pods`.

---

## **Lancement de GitHub et Configuration CI/CD**
Le projet est h√©berg√© sur **GitHub**, et un **workflow CI/CD** a √©t√© mis en place pour :
1. **Build de l'image Docker**
2. **Push sur DockerHub**
3. **D√©ploiement automatique sur Kubernetes**

Workflow dans `.github/workflows/deploy.yml` :
```yaml
- name: Build de l'image Docker
  run: docker build -t locquetr123/dash-app:latest .

- name: Push de l'image Docker
  run: docker push locquetr123/dash-app:latest

- name: D√©ployer MongoDB, Elasticsearch et l'application Dash sur Kubernetes
  run: |
    kubectl apply -f kubernetes/mongodb-deployment.yaml
    kubectl apply -f kubernetes/elasticsearch-deployment.yaml
    kubectl apply -f kubernetes/app-deployment.yaml
```
üìå *Image du pipeline CI/CD en action*

Ces deux images que l'ont peut voir dans le dossier action de github nous montre que le projet marche et nous explique les √©tapes (docker-compose, Elastic) qui le font tourner

![](Images/Reussite_CI_CD.png)

![](Images/Info_CI_CD.png)

---

## **Installation des packages**
Une fois sur le serveur AWS, j'ai install√© les d√©pendances n√©cessaires :
```sh
sudo yum update -y
sudo yum install docker -y
sudo systemctl start docker
sudo systemctl enable docker
```
Ensuite, installation de **kubectl**, **eksctl** et **AWS CLI** pour g√©rer Kubernetes :
```sh
curl -O https://s3.us-west-2.amazonaws.com/amazon-eks/1.27.0/2023-05-05/bin/linux/amd64/kubectl
chmod +x kubectl
sudo mv kubectl /usr/local/bin/
```

---
## Importation des donnees dans Elasticsearch
Les donn√©es de performances en marathon ont √©t√© import√©es dans Elasticsearch depuis des fichiers CSV :
```sh
docker exec -i elasticsearch curl -X PUT "http://localhost:9200/athle_results" -H "Content-Type: application/json" -d' {
  "settings": { "number_of_shards": 1, "number_of_replicas": 1 }
}'
```
Puis, chargement des donn√©es :
```sh
curl -X POST "http://localhost:9200/athle_results/_bulk" -H "Content-Type: application/json" --data-binary @data/athle_results.json
```

## Creation du Cluster Kubernetes
Le cluster Kubernetes a √©t√© d√©ploy√© sur AWS EKS via la commande :
```sh
eksctl create cluster --name devops-cluster --region us-east-1 --nodegroup-name standard-workers --node-type m5.large --nodes 2
```
Ensuite, les services et pods ont √©t√© d√©ploy√©s avec :
```sh
kubectl apply -f kubernetes/
```
üìå *Image des services Kubernetes*

![](Images/IP_Kubernetes_1.png)
![](Images/IP_Kubernetes_2.png)

Ici on peut voir les deux IP de mes instances cr√©es via Kubernetes

![](Images/Instance_Kubernetes.png)

Ici on peut nos deux instances de type large pour subvenir √† nos besoins

![](Images/Instance_Kubernetes_2.png)

Sur le terminal on peut en tappant la commande *kubectl get nodes -o wide* nos deux nodes equivalentes √† des conteneurs kubernetes

![](Images/Service_Kubernetes.png)

Sur le terminal on peut en tappant la commande *get services*, on obtient les services (images) de notre r√©seau

![](Images/Etat_Instance_Kubernetes.png)

Sur le terminal on peut en tappant la commande *kubectl get podsds*, on obtient toutes les images de notre docker-compose

![](Images/Etat_Deux_Instances_Kubernetes.png)

Enfin, sur AWS, on peut analyser nos deux instances, via ce graph

## **Configuration et explication des fichiers Kubernetes**

### **Dash App**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dash-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: dash
  template:
    metadata:
      labels:
        app: dash
    spec:
      containers:
      - name: dash
        image: locquetr123/dash-app:latest  
        env:
        - name: MONGO_URI
          value: "mongodb://mongodb-service:27017/"
        - name: ELASTICSEARCH_URL
          value: "http://elasticsearch-service:9200"
        ports:
        - containerPort: 8060
---
apiVersion: v1
kind: Service
metadata:
  name: dash-service
spec:
  selector:
    app: dash
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8060
  type: LoadBalancer
```


---

## **Acces a lapplication**
```sh
kubectl get services dash-service
```
Acc√®s :
```
http://<EXTERNAL-IP>:8060
```

---



## Conclusion
Ce projet m'a permis d'automatiser le d√©ploiement d'une application de DataViz avec **Dash**, en utilisant un pipeline CI/CD sur AWS et Kubernetes. J'ai pu ouvrir un serveur, et ainsi cr√©e un premier projet r√©element professionelle. J'esp√®re √† l'avenir compl√©ter ce projet afin qu'il offre une approche compl√®te de la mise en production et de la gestion de bases de donn√©es √† grande √©chelle. Le sujet me passionne, et c'est la premi√®re fois que j'ai pu alli√© ma passion (la course √† pied) et un projet de Devops.
Pour plus d'information sur l'application en elle m√™me, veuillez ouvrir la vid√©o explicative

---

